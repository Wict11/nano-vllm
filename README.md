# Nano-vLLM

åŸºäºnana-vLLMï¼Œå®ç°ä¸€äº›åŠŸèƒ½ã€‚
* **æ”¯æŒQwen3ã€Qwen-MoEã€LLama2çš„æ¨¡å‹**
* **æ·»åŠ chunked prefillåŠŸèƒ½**
* **æ·»åŠ å¼‚æ­¥è°ƒåº¦åŠŸèƒ½**
* **å…¶ä»–åŠŸèƒ½å®ç°ä¸­ã€‚ã€‚**

## Chunked Prefill è®¾è®¡é€»è¾‘

* ğŸš€ **Scheduler layer** - ä¸ºé•¿åºåˆ—åˆ‡åˆ†chunkå¹¶æ·»åŠ è‡³è°ƒåº¦é˜Ÿåˆ—ï¼Œä¼˜å…ˆçº§ä¾æ¬¡æ˜¯ï¼šrunningé˜Ÿåˆ—ä¸­çš„prefillé˜¶æ®µåºåˆ—ã€waitingé˜Ÿåˆ—ä¸­çš„åºåˆ—ã€runningé˜Ÿåˆ—ä¸­decodeé˜¶æ®µçš„åºåˆ—
* ğŸ“– **LLM engine layer** - é¢å¤–ä¼ å…¥num_prefill_tokenså’Œnum_decode_tokensæ•°æ®ï¼ŒåŒºåˆ†æ··åˆprefillå’Œdecodeçš„æ‰¹æ¬¡
* ğŸ’¡ **Attention layer** - é’ˆå¯¹æ··åˆæ‰¹æ¬¡ï¼Œåˆ†åˆ«è°ƒç”¨flash attnçš„å‡½æ•°æ¥å£æ¥å¤„ç†ï¼Œæœ€ååˆå¹¶æ•°æ®å¹¶è¿”å›
* ğŸ’¡ **Post progress** - åªæœ‰decodeé˜¶æ®µåºåˆ—è¦è®¡ç®—logitså’Œæ›´æ–°äº§ç”Ÿçš„token

## å¼‚æ­¥è°ƒåº¦è®¾è®¡é€»è¾‘
**è¯¦æƒ…è¯·çœ‹ASYNC_GUIDE.mdæ–‡ä»¶**

## Installation

```bash
pip install git+https://github.com/Wict11/nano-vllm.git
```

## Manual Download

If you prefer to download the model weights manually, use the following command:
```bash
huggingface-cli download --resume-download Qwen/Qwen3-0.6B \
  --local-dir ~/huggingface/Qwen3-0.6B/ \
  --local-dir-use-symlinks False
```

## Quick Start

See `example.py` for usage. The API mirrors vLLM's interface with minor differences in the `LLM.generate` method:
```python
from nanovllm import LLM, SamplingParams
llm = LLM("/YOUR/MODEL/PATH", enforce_eager=True, tensor_parallel_size=1)
sampling_params = SamplingParams(temperature=0.6, max_tokens=256)
prompts = ["Hello, Nano-vLLM."]
outputs = llm.generate(prompts, sampling_params)
outputs[0]["text"]
```

## Benchmark

**0.Test Configuration:**
- Hardware: A10 (24GB)
- Model: Qwen3-0.6B
- Total Requests: 3 sequencesï¼ˆfor testï¼‰
- short background flows(~20tokens): 5
- long incast flows(~1000tokens): 5

**1.chunked prefillæ€§èƒ½ç»“æœï¼š**
* **æµé‡æƒ…å†µï¼š**
äº”ä¸ªèƒŒæ™¯çŸ­æµï¼ˆ20tokensï¼‰
äº”ä¸ªincasté•¿æµï¼ˆ1000tokensï¼‰
* **Disabled Chunked Prefill:**
<img width="1198" height="437" alt="image" src="https://github.com/user-attachments/assets/953d9f9f-c954-4bd3-8d6e-602a14f8e981" />

<img width="679" height="226" alt="image" src="https://github.com/user-attachments/assets/3d7a35a9-7d87-4cbc-a9aa-d0b250618f9e" />

* **Chunk_size = 512:**
  <img width="1188" height="438" alt="image" src="https://github.com/user-attachments/assets/93109a4d-580f-4f01-991c-36cf22909430" />

  <img width="736" height="201" alt="image" src="https://github.com/user-attachments/assets/4c8d25f2-900a-4152-a163-916c192f0281" />
* **ç»“æœåˆ†æï¼š**
  å¯¹æ··åˆæ‰¹æ¬¡çš„decodeåºåˆ—æ€§èƒ½å½±å“ï¼šå¼€chunked prefillåï¼Œæœ€å¤§TPOTå‡å°‘ï½4.8xï¼Œ
  å¯¹æ··åˆæ‰¹æ¬¡çš„prefillåºåˆ—æ€§èƒ½å½±å“ï¼šå¼€chunked prefillåï¼ŒTTFTè‡³å¤šå¢åŠ ï½1.5x
  
* **å¾…åšæµ‹è¯•ï¼šæœ€å¤§å¯æ”¯æŒé•¿åº¦**
  ä¸å¼€chunked prefillæœ€å¤§èƒ½æ”¯æŒçš„åºåˆ—é•¿åº¦ä¸ºï¼šxxx
  å¼€äº†chunked prefillæœ€å¤§èƒ½æ”¯æŒçš„åºåˆ—é•¿åº¦ä¸ºï¼šxxxï¼Œæå‡xxxå€
  
**2.å¼‚æ­¥è°ƒåº¦æ€§èƒ½ç»“æœï¼š**
ã€‚ã€‚ã€‚



